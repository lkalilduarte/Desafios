{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de bibliotecas e do dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from tabulate import tabulate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Os arquivos csv estão sendo importados do repositório do GitHub\n",
    "data_estacao_convencional_read = pd.read_csv('Estacao_Convencional.csv')\n",
    "data_sensor_read = pd.read_csv('Sensor_FieldPRO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime – utc</th>\n",
       "      <th>air_humidity_100</th>\n",
       "      <th>air_temperature_100</th>\n",
       "      <th>atm_pressure_main</th>\n",
       "      <th>num_of_resets</th>\n",
       "      <th>piezo_charge</th>\n",
       "      <th>piezo_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30T23:00:00Z</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.366</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>45123</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-01T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>45025</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-01T01:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.366</td>\n",
       "      <td>9419</td>\n",
       "      <td>0</td>\n",
       "      <td>44923</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-01T02:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.322</td>\n",
       "      <td>9419</td>\n",
       "      <td>0</td>\n",
       "      <td>44825</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-01T03:00:00Z</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.240</td>\n",
       "      <td>9416</td>\n",
       "      <td>0</td>\n",
       "      <td>44728</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-01T04:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.828</td>\n",
       "      <td>9411</td>\n",
       "      <td>0</td>\n",
       "      <td>44632</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-01T05:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9411</td>\n",
       "      <td>0</td>\n",
       "      <td>44537</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-10-01T06:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.686</td>\n",
       "      <td>9413</td>\n",
       "      <td>0</td>\n",
       "      <td>44441</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-01T07:00:00Z</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.630</td>\n",
       "      <td>9415</td>\n",
       "      <td>0</td>\n",
       "      <td>44347</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01T08:00:00Z</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.588</td>\n",
       "      <td>9419</td>\n",
       "      <td>0</td>\n",
       "      <td>44251</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-10-01T09:00:00Z</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.474</td>\n",
       "      <td>9425</td>\n",
       "      <td>0</td>\n",
       "      <td>44156</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-10-01T11:00:00Z</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.332</td>\n",
       "      <td>9438</td>\n",
       "      <td>0</td>\n",
       "      <td>43968</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-10-01T12:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9438</td>\n",
       "      <td>0</td>\n",
       "      <td>43874</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-01T13:00:00Z</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.474</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>43778</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-10-01T14:00:00Z</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.516</td>\n",
       "      <td>9432</td>\n",
       "      <td>0</td>\n",
       "      <td>43682</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-10-01T15:00:00Z</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.346</td>\n",
       "      <td>9460</td>\n",
       "      <td>0</td>\n",
       "      <td>43581</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-10-01T16:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9460</td>\n",
       "      <td>0</td>\n",
       "      <td>43259</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-10-01T18:00:00Z</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.502</td>\n",
       "      <td>9473</td>\n",
       "      <td>0</td>\n",
       "      <td>42402</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-10-01T19:38:34.924000Z</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.018</td>\n",
       "      <td>9378</td>\n",
       "      <td>0</td>\n",
       "      <td>42084</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-10-01T20:00:00Z</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.910</td>\n",
       "      <td>9379</td>\n",
       "      <td>0</td>\n",
       "      <td>42033</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-10-01T21:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9379</td>\n",
       "      <td>0</td>\n",
       "      <td>41914</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-10-01T22:00:00Z</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.884</td>\n",
       "      <td>9389</td>\n",
       "      <td>0</td>\n",
       "      <td>41799</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-10-01T23:00:00Z</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.276</td>\n",
       "      <td>9394</td>\n",
       "      <td>0</td>\n",
       "      <td>41708</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-10-02T00:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.490</td>\n",
       "      <td>9394</td>\n",
       "      <td>0</td>\n",
       "      <td>41621</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-10-02T01:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.980</td>\n",
       "      <td>9401</td>\n",
       "      <td>0</td>\n",
       "      <td>41539</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-10-02T03:00:00Z</td>\n",
       "      <td>57.0</td>\n",
       "      <td>22.626</td>\n",
       "      <td>9400</td>\n",
       "      <td>0</td>\n",
       "      <td>41395</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-10-02T04:00:00Z</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.922</td>\n",
       "      <td>9396</td>\n",
       "      <td>0</td>\n",
       "      <td>41330</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-10-02T05:00:00Z</td>\n",
       "      <td>66.0</td>\n",
       "      <td>20.670</td>\n",
       "      <td>9398</td>\n",
       "      <td>0</td>\n",
       "      <td>41267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-10-02T06:00:00Z</td>\n",
       "      <td>61.0</td>\n",
       "      <td>22.116</td>\n",
       "      <td>9397</td>\n",
       "      <td>0</td>\n",
       "      <td>41204</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-10-02T07:00:00Z</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20.358</td>\n",
       "      <td>9398</td>\n",
       "      <td>0</td>\n",
       "      <td>41142</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-10-02T08:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9398</td>\n",
       "      <td>0</td>\n",
       "      <td>41083</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-10-02T09:00:00Z</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.862</td>\n",
       "      <td>9407</td>\n",
       "      <td>0</td>\n",
       "      <td>41023</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-10-02T10:00:00Z</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.356</td>\n",
       "      <td>9414</td>\n",
       "      <td>0</td>\n",
       "      <td>40964</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-10-02T11:00:00Z</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.108</td>\n",
       "      <td>9422</td>\n",
       "      <td>0</td>\n",
       "      <td>40891</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-10-02T12:00:00Z</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.518</td>\n",
       "      <td>9425</td>\n",
       "      <td>0</td>\n",
       "      <td>40789</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-10-02T14:00:00Z</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.684</td>\n",
       "      <td>9422</td>\n",
       "      <td>0</td>\n",
       "      <td>40533</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-10-02T15:00:00Z</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.396</td>\n",
       "      <td>9415</td>\n",
       "      <td>0</td>\n",
       "      <td>40391</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-10-02T16:00:00Z</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.156</td>\n",
       "      <td>9408</td>\n",
       "      <td>0</td>\n",
       "      <td>40235</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-10-02T17:00:00Z</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42.520</td>\n",
       "      <td>9399</td>\n",
       "      <td>0</td>\n",
       "      <td>40075</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-10-02T18:00:00Z</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.984</td>\n",
       "      <td>9393</td>\n",
       "      <td>0</td>\n",
       "      <td>39915</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-10-02T19:00:00Z</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.868</td>\n",
       "      <td>9387</td>\n",
       "      <td>0</td>\n",
       "      <td>39760</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-10-02T20:00:00Z</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.968</td>\n",
       "      <td>9387</td>\n",
       "      <td>0</td>\n",
       "      <td>39622</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-10-02T21:00:00Z</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.740</td>\n",
       "      <td>9391</td>\n",
       "      <td>0</td>\n",
       "      <td>39495</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-10-02T22:00:00Z</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.566</td>\n",
       "      <td>9395</td>\n",
       "      <td>0</td>\n",
       "      <td>39392</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-10-02T23:00:00Z</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.134</td>\n",
       "      <td>9403</td>\n",
       "      <td>0</td>\n",
       "      <td>39302</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-10-03T00:00:00Z</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.480</td>\n",
       "      <td>9408</td>\n",
       "      <td>0</td>\n",
       "      <td>39217</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-10-03T01:00:00Z</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.386</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>39137</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-10-03T02:00:00Z</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.774</td>\n",
       "      <td>9414</td>\n",
       "      <td>0</td>\n",
       "      <td>39064</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-10-03T03:00:00Z</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.132</td>\n",
       "      <td>9413</td>\n",
       "      <td>0</td>\n",
       "      <td>38994</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-10-03T04:00:00Z</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.872</td>\n",
       "      <td>9412</td>\n",
       "      <td>0</td>\n",
       "      <td>38925</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime – utc  air_humidity_100  air_temperature_100  \\\n",
       "0          2020-09-30T23:00:00Z              38.0               31.366   \n",
       "1          2020-10-01T00:00:00Z               NaN                  NaN   \n",
       "2          2020-10-01T01:00:00Z              39.0               31.366   \n",
       "3          2020-10-01T02:00:00Z              39.0               31.322   \n",
       "4          2020-10-01T03:00:00Z              38.0               31.240   \n",
       "5          2020-10-01T04:00:00Z              39.0               30.828   \n",
       "6          2020-10-01T05:00:00Z               NaN                  NaN   \n",
       "7          2020-10-01T06:00:00Z              39.0               30.686   \n",
       "8          2020-10-01T07:00:00Z              40.0               30.630   \n",
       "9          2020-10-01T08:00:00Z              41.0               30.588   \n",
       "10         2020-10-01T09:00:00Z              41.0               30.474   \n",
       "11         2020-10-01T11:00:00Z              44.0               30.332   \n",
       "12         2020-10-01T12:00:00Z               NaN                  NaN   \n",
       "13         2020-10-01T13:00:00Z              44.0               30.474   \n",
       "14         2020-10-01T14:00:00Z              44.0               30.516   \n",
       "15         2020-10-01T15:00:00Z              44.0               30.346   \n",
       "16         2020-10-01T16:00:00Z               NaN                  NaN   \n",
       "17         2020-10-01T18:00:00Z              30.0               34.502   \n",
       "18  2020-10-01T19:38:34.924000Z              20.0               39.018   \n",
       "19         2020-10-01T20:00:00Z              22.0               37.910   \n",
       "20         2020-10-01T21:00:00Z               NaN                  NaN   \n",
       "21         2020-10-01T22:00:00Z              32.0               30.884   \n",
       "22         2020-10-01T23:00:00Z              34.0               30.276   \n",
       "23         2020-10-02T00:00:00Z              39.0               28.490   \n",
       "24         2020-10-02T01:00:00Z              39.0               27.980   \n",
       "25         2020-10-02T03:00:00Z              57.0               22.626   \n",
       "26         2020-10-02T04:00:00Z              62.0               22.922   \n",
       "27         2020-10-02T05:00:00Z              66.0               20.670   \n",
       "28         2020-10-02T06:00:00Z              61.0               22.116   \n",
       "29         2020-10-02T07:00:00Z              70.0               20.358   \n",
       "30         2020-10-02T08:00:00Z               NaN                  NaN   \n",
       "31         2020-10-02T09:00:00Z              69.0               19.862   \n",
       "32         2020-10-02T10:00:00Z              62.0               22.356   \n",
       "33         2020-10-02T11:00:00Z              39.0               30.108   \n",
       "34         2020-10-02T12:00:00Z              28.0               34.518   \n",
       "35         2020-10-02T14:00:00Z              23.0               37.684   \n",
       "36         2020-10-02T15:00:00Z              19.0               40.396   \n",
       "37         2020-10-02T16:00:00Z              17.0               42.156   \n",
       "38         2020-10-02T17:00:00Z              16.0               42.520   \n",
       "39         2020-10-02T18:00:00Z              16.0               41.984   \n",
       "40         2020-10-02T19:00:00Z              18.0               39.868   \n",
       "41         2020-10-02T20:00:00Z              18.0               39.968   \n",
       "42         2020-10-02T21:00:00Z              23.0               35.740   \n",
       "43         2020-10-02T22:00:00Z              29.0               31.566   \n",
       "44         2020-10-02T23:00:00Z              31.0               30.134   \n",
       "45         2020-10-03T00:00:00Z              33.0               29.480   \n",
       "46         2020-10-03T01:00:00Z              44.0               25.386   \n",
       "47         2020-10-03T02:00:00Z              53.0               23.774   \n",
       "48         2020-10-03T03:00:00Z              46.0               25.132   \n",
       "49         2020-10-03T04:00:00Z              62.0               21.872   \n",
       "\n",
       "    atm_pressure_main  num_of_resets  piezo_charge  piezo_temperature  \n",
       "0                9412              0         45123                 30  \n",
       "1                9412              0         45025                 31  \n",
       "2                9419              0         44923                 31  \n",
       "3                9419              0         44825                 31  \n",
       "4                9416              0         44728                 31  \n",
       "5                9411              0         44632                 30  \n",
       "6                9411              0         44537                 30  \n",
       "7                9413              0         44441                 30  \n",
       "8                9415              0         44347                 30  \n",
       "9                9419              0         44251                 30  \n",
       "10               9425              0         44156                 30  \n",
       "11               9438              0         43968                 30  \n",
       "12               9438              0         43874                 30  \n",
       "13               9437              0         43778                 30  \n",
       "14               9432              0         43682                 30  \n",
       "15               9460              0         43581                 30  \n",
       "16               9460              0         43259                 30  \n",
       "17               9473              0         42402                 35  \n",
       "18               9378              0         42084                 38  \n",
       "19               9379              0         42033                 39  \n",
       "20               9379              0         41914                 37  \n",
       "21               9389              0         41799                 31  \n",
       "22               9394              0         41708                 28  \n",
       "23               9394              0         41621                 27  \n",
       "24               9401              0         41539                 26  \n",
       "25               9400              0         41395                 22  \n",
       "26               9396              0         41330                 21  \n",
       "27               9398              0         41267                 20  \n",
       "28               9397              0         41204                 20  \n",
       "29               9398              0         41142                 20  \n",
       "30               9398              0         41083                 19  \n",
       "31               9407              0         41023                 19  \n",
       "32               9414              0         40964                 18  \n",
       "33               9422              0         40891                 24  \n",
       "34               9425              0         40789                 32  \n",
       "35               9422              0         40533                 40  \n",
       "36               9415              0         40391                 42  \n",
       "37               9408              0         40235                 45  \n",
       "38               9399              0         40075                 46  \n",
       "39               9393              0         39915                 45  \n",
       "40               9387              0         39760                 44  \n",
       "41               9387              0         39622                 41  \n",
       "42               9391              0         39495                 38  \n",
       "43               9395              0         39392                 32  \n",
       "44               9403              0         39302                 28  \n",
       "45               9408              0         39217                 27  \n",
       "46               9412              0         39137                 25  \n",
       "47               9414              0         39064                 23  \n",
       "48               9413              0         38994                 22  \n",
       "49               9412              0         38925                 22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando os dados do Sensor FieldPRO, as primeiras 50 linhas\n",
    "data_sensor_read.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime – utc          object\n",
       "air_humidity_100       float64\n",
       "air_temperature_100    float64\n",
       "atm_pressure_main        int64\n",
       "num_of_resets            int64\n",
       "piezo_charge             int64\n",
       "piezo_temperature        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identificando o tipo dos dados nas colunas dataframe Sensor FieldPRO, usando o dtypes\n",
    "data_sensor_read.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 6, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se existem valores nan e contá-los do dataframe Sensor FieldPRO\n",
    "#Criando uma lista vazia para receber a contagem dos valores NaN\n",
    "\n",
    "valores_nan_sensor_fieldpro = []\n",
    "\n",
    "#O FOR é usado para passar por todos os valores do dataframe\n",
    "for coluna in data_sensor_read.columns:\n",
    "  #A contagem acontece se o isna identifica que é um valor NaN\n",
    "  contagem_nan_sensor_fieldpro = data_sensor_read.loc[pd.isna(data_sensor_read[coluna]), coluna].shape[0]\n",
    "\n",
    "  #O append coloca o valor da contagem na lista que estava vazia\n",
    "  valores_nan_sensor_fieldpro.append(contagem_nan_sensor_fieldpro)\n",
    "\n",
    "valores_nan_sensor_fieldpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 6, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se existem valores null do dataframe Sensor FieldPRO\n",
    "\n",
    "#Criando uma lista vazia para receber a contagem dos valores Null\n",
    "valores_null_sensor_fieldpro = []\n",
    "\n",
    "#O FOR é usado para passar por todos os valores do dataframe\n",
    "for coluna in data_sensor_read.columns:\n",
    "  #A contagem acontece se o isna identifica que é um valor NaN\n",
    "  contagem_null_sensor_fieldpro = data_sensor_read.loc[pd.isnull(data_sensor_read[coluna]), coluna].shape[0]\n",
    "  #O append coloca o valor da contagem na lista que estava vazia\n",
    "  valores_null_sensor_fieldpro.append(contagem_null_sensor_fieldpro)\n",
    "\n",
    "valores_null_sensor_fieldpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O resultado das duas verificações foi o mesmo, indicando que os valores que estão sendo\n",
    "# identificados como NaN são os mesmos que estão sendo identificados como Null\n",
    "# portanto só será necessário um tratamento para esses valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foram identificados 6 valores NaN, tanto na coluna air_humidity_100 quanto na air_temperature_100\n",
    "#Agora será feito um tratamento para substituir os valores NaN pela média dos valores de temperatura do ar ou humidade do ar nos\n",
    "# horários adjacentes, por exemplo no horário 2020-10-01T00:00:00Z\tos valores de temperatura do ar e humadidade do ar são NaN\n",
    "# eles serão substituidos pela média dos valores de temperatura do ar e humidade do ar dos horários 2020-09-30T23:00:00Z\n",
    "# e 2020-10-01T01:00:00Z, que são o horário antes e o depois da ocorrência do valor NaN\n",
    "#O objetivo é substituir os valores NaN pois eles interferem nos cáculos e modelos que serão desenvolvidos mais a abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma lista com os valores da coluna de humidade do ar para poder substituir os valores NaN\n",
    "lista_air_humidity_original = list(data_sensor_read['air_humidity_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR é usado para verificar quais são os valores NaN e substuir pela média dos valores anterior e posterior\n",
    "#Para a coluna de humidade do ar\n",
    "\n",
    "#Criando uma lista vazia para receber os valores certos da coluna\n",
    "lista_air_humidity_semNaN = []\n",
    "for i in range(len(lista_air_humidity_original)):\n",
    "  #O IF verifica a condição do valor ser NaN\n",
    "  if pd.isna(lista_air_humidity_original[i]) == True :\n",
    "    #Caso seja NaN o valor é subsituido pela média dos adjacentes\n",
    "    lista_air_humidity_original[i] = (lista_air_humidity_original[i-1] + lista_air_humidity_original[i+1])/2\n",
    "  #Caso não seja NaN o valor continua o mesmo\n",
    "  lista_air_humidity_semNaN.append(lista_air_humidity_original[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma lista com os valores da coluna de temperatura do ar para poder substituir os valores NaN\n",
    "lista_air_temperature_original = list(data_sensor_read['air_temperature_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR é usado para verificar quais são os valores NaN e substuir pela média dos valores anterior e posterior\n",
    "#Para a coluna de temperatura do ar\n",
    "\n",
    "#Criando uma lista vazia para receber os valores certos da coluna\n",
    "lista_air_temperature_semNaN = []\n",
    "for i in range(len(lista_air_temperature_original)):\n",
    "  #O IF verifica a condição do valor ser NaN\n",
    "  if pd.isna(lista_air_temperature_original[i]) == True :\n",
    "    #Caso seja NaN o valor é subsituido pela média dos adjacentes\n",
    "    lista_air_temperature_original[i] = (lista_air_temperature_original[i-1] + lista_air_temperature_original[i+1])/2\n",
    "  #Caso não seja NaN o valor continua o mesmo\n",
    "  lista_air_temperature_semNaN.append(lista_air_temperature_original[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo as listas sem valores NaN no lugar das colunas originais\n",
    "data_sensor_read['air_humidity_100'] = lista_air_humidity_semNaN\n",
    "data_sensor_read['air_temperature_100'] = lista_air_temperature_semNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifiquei visualmente que um dos horários está fora do padrão de 00 minutos e 00 segundos\n",
    "# como irei usar a coluna 'Datetime – utc'\tcomo uma coluna chave os valores precisam estar no padrão\n",
    "#Os caracteres de minuto e segundo do horário ficam nas posições de 14 a 19, então esses serão os\n",
    "# caracteres verificados para padronizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma lista com os valores da coluna de datetime para poder padronizar os valores de horário\n",
    "lista_datetime_original = list(data_sensor_read['Datetime – utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR é usado para verificar quais são os valores com caracteres de minuto e segundo fora do padrão 00:00\n",
    "# e substuir por 00:00\n",
    "\n",
    "#Criando uma lista vazia para receber os valores certos da coluna\n",
    "lista_datetime_padrao = []\n",
    "for i in range(len(lista_datetime_original)):\n",
    "  #O STR transforma o valor em string para que seja possível trabalhar com o valor\n",
    "  # como uma string\n",
    "  str(lista_datetime_original[i])\n",
    "  #O IF verifica a condição do valor ter caracteres diferentes de 00:00 nas\n",
    "  # posições 14 a 19\n",
    "  if (lista_datetime_original[i][14:19]) != '00:00':\n",
    "    #Caso seja diferente de 00:00 o valor é subsituido por 00:00\n",
    "    lista_datetime_original[i] = lista_datetime_original[i][:14] + '00:00Z'\n",
    "  #Caso esteja no padrão o valor continua o mesmo\n",
    "  lista_datetime_padrao.append(lista_datetime_original[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo a lista com datetime padronizado no dataframe Sensor FieldPRO\n",
    "data_sensor_read['Datetime – utc'] = lista_datetime_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entre as colunas numéricas do dataframe apenas as relativas a temperatura\n",
    "# poderiam incluir valores negativos, ou seja, as colunas air_temperature_100\n",
    "# e piezo_temperature podem ter valores negativos\n",
    "#A humidade do ar, a pressão atmosférica, numéro de resets e a carga acumulada\n",
    "# não poderiam ter valores negativos, portanto as colunas air_humidity_100,\n",
    "#\tatm_pressure_main, num_of_resets e piezo_charge devem ter apenas valores positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um dataframe apenas com as colunas que não podem ter valores negativos\n",
    "data_sensor_numerics = data_sensor_read[['air_humidity_100',\t'atm_pressure_main',\t'num_of_resets',\t'piezo_charge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se existem valores negativos nas colunas\n",
    "\n",
    "#Criando uma lista vazia para receber a contagem dos valores negativos\n",
    "valores_negativos_sensor_fieldpro = []\n",
    "#O FOR é usado para passar por todos os valores do dataframe\n",
    "for coluna in data_sensor_numerics:\n",
    "  #A contagem é feita caso o valor seja menor que zero\n",
    "  contagem_negativos_sensor_fieldpro = len(data_sensor_numerics.loc[data_sensor_numerics[coluna] < 0])\n",
    "  #O resultado da contagem é adicionado a lista que estava vazia\n",
    "  valores_negativos_sensor_fieldpro.append(contagem_negativos_sensor_fieldpro)\n",
    "\n",
    "valores_negativos_sensor_fieldpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concluisse que não há valores negativos em colunas que não poderiam os ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustando o nome da coluna 'Datetime - utc' do dataframe Sensor FiledPRO pois é\n",
    "# melhor que o nome da coluna não tenha espaços entre as palavras\n",
    "data_sensor_read = data_sensor_read.rename(columns={\"Datetime – utc\": \"Datetime\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um novo dataframe Sensor FieldPRO que indica que é a versão pronta para análises\n",
    "data_sensor_pronto = data_sensor_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fim da análise dos dados e ajuste do dataframe Sensor FieldPRO\n",
    "#Início da análise do dataframe da Estação Convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Hora (Brasília)</th>\n",
       "      <th>chuva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          data Hora (Brasília)  chuva\n",
       "0   2020-09-01        00:00:00    0.0\n",
       "1   2020-09-01        01:00:00    0.0\n",
       "2   2020-09-01        02:00:00    0.0\n",
       "3   2020-09-01        03:00:00    0.0\n",
       "4   2020-09-01        04:00:00    0.0\n",
       "5   2020-09-01        05:00:00    0.0\n",
       "6   2020-09-01        06:00:00    0.0\n",
       "7   2020-09-01        07:00:00    0.0\n",
       "8   2020-09-01        08:00:00    0.0\n",
       "9   2020-09-01        09:00:00    0.0\n",
       "10  2020-09-01        10:00:00    0.0\n",
       "11  2020-09-01        11:00:00    0.0\n",
       "12  2020-09-01        12:00:00    0.0\n",
       "13  2020-09-01        13:00:00    0.0\n",
       "14  2020-09-01        14:00:00    0.0\n",
       "15  2020-09-01        15:00:00    0.0\n",
       "16  2020-09-01        16:00:00    0.0\n",
       "17  2020-09-01        17:00:00    0.0\n",
       "18  2020-09-01        18:00:00    0.0\n",
       "19  2020-09-01        19:00:00    0.0\n",
       "20  2020-09-01        20:00:00    0.0\n",
       "21  2020-09-01        21:00:00    0.0\n",
       "22  2020-09-01        22:00:00    0.0\n",
       "23  2020-09-01        23:00:00    0.0\n",
       "24  2020-09-02        00:00:00    0.0\n",
       "25  2020-09-02        01:00:00    0.0\n",
       "26  2020-09-02        02:00:00    0.0\n",
       "27  2020-09-02        03:00:00    0.0\n",
       "28  2020-09-02        04:00:00    0.0\n",
       "29  2020-09-02        05:00:00    0.0\n",
       "30  2020-09-02        06:00:00    0.0\n",
       "31  2020-09-02        07:00:00    0.0\n",
       "32  2020-09-02        08:00:00    0.0\n",
       "33  2020-09-02        09:00:00    0.0\n",
       "34  2020-09-02        10:00:00    0.0\n",
       "35  2020-09-02        11:00:00    0.0\n",
       "36  2020-09-02        12:00:00    0.0\n",
       "37  2020-09-02        13:00:00    0.0\n",
       "38  2020-09-02        14:00:00    0.0\n",
       "39  2020-09-02        15:00:00    0.0\n",
       "40  2020-09-02        16:00:00    0.0\n",
       "41  2020-09-02        17:00:00    0.0\n",
       "42  2020-09-02        18:00:00    0.0\n",
       "43  2020-09-02        19:00:00    0.0\n",
       "44  2020-09-02        20:00:00    0.0\n",
       "45  2020-09-02        21:00:00    0.0\n",
       "46  2020-09-02        22:00:00    0.0\n",
       "47  2020-09-02        23:00:00    0.0\n",
       "48  2020-09-03        00:00:00    0.0\n",
       "49  2020-09-03        01:00:00    0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando os dados do dataframe da Estação Convencional\n",
    "data_estacao_convencional_read.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                object\n",
       "Hora (Brasília)     object\n",
       "chuva              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identificando o tipo dos dados nas colunas do dataframe Estação Convencional\n",
    "data_estacao_convencional_read.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se existem valores NaN e contá-los do dataframe Estação Convencional\n",
    "\n",
    "#Criando uma lista vazia para receber a contagem dos valores NaN\n",
    "valores_nan_estacao_convencional = []\n",
    "#O FOR é usado para passar por todos os valores do dataframe\n",
    "for coluna in data_estacao_convencional_read.columns:\n",
    "  #A contagem acontece se o isna identifica que é um valor NaN\n",
    "  contagem_nan_estacao_convencional = data_estacao_convencional_read.loc[pd.isna(data_estacao_convencional_read[coluna]), coluna].shape[0]\n",
    "  #O append coloca o valor da contagem na lista que estava vazia\n",
    "  valores_nan_estacao_convencional.append(contagem_nan_estacao_convencional)\n",
    "\n",
    "valores_nan_estacao_convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não há valores NaN nesse dataframe\n",
    "#Agora será feita a verificação se há valores negativos de chuva, pois não deveriam existir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um dataframe apenas com a coluna de chuva\n",
    "data_estacao_convencional_numerics = data_estacao_convencional_read[['chuva']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se existem valores negativos na coluna chuva\n",
    "\n",
    "#Criando uma lista vazia para receber a contagem dos valores negativos\n",
    "valores_negativos_estacao_convencional = []\n",
    "\n",
    "#O FOR é usado para passar por todos os valores do dataframe\n",
    "for coluna in data_estacao_convencional_numerics:\n",
    "  #A contagem acontece se o valor é menor que zero\n",
    "  contagem_negativos_estacao_convencional = len(data_estacao_convencional_numerics.loc[data_estacao_convencional_numerics[coluna] < 0])\n",
    "  #O append coloca o valor da contagem na lista que estava vazia\n",
    "  valores_negativos_estacao_convencional.append(contagem_negativos_estacao_convencional)\n",
    "\n",
    "valores_negativos_estacao_convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não há valores negativos na coluna chuva\n",
    "#Agora será feito uma concatenação e ajuste entre as colunas data e Hora (Brasília)\n",
    "# do dataframe Estação Convencional para criar uma coluna no mesmo padrão que a\n",
    "# coluna 'Datetime'\tdo dataframe Sensor FieldPRO, pois irei usar essas duas\n",
    "# colunas para relacionar os dois dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As listas com os valores das coluas de data e Hora (Brasília) do dataframe Estação\n",
    "# Convencional foram criadas para execurtar o FOR abaixo\n",
    "lista_data_estacao_convencional = data_estacao_convencional_read['data']\n",
    "lista_horario_estacao_convencional = data_estacao_convencional_read['Hora (Brasília)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR é usado para juntar os valores das colunas data e Hora (Brasília) do dataframe Estação Convencional\n",
    "# e deixar no no mesmo formato que a coluna 'Datetime' do dataframe Sensor FielPRO\n",
    "\n",
    "#Criando uma lista vazia para receber a contagem dos valores NaN\n",
    "lista_datatime_estacao_convencional = []\n",
    "#O FOR passa por cada linha do dataframe Estação Convencional\n",
    "for i in range(len(lista_data_estacao_convencional)):\n",
    "  #Um valor é criando concatenando a data, a letra T, o horário e a letra Z\n",
    "  # para ficar no padrão\n",
    "  datetime_estacao_convencional = lista_data_estacao_convencional[i] + 'T' + lista_horario_estacao_convencional[i] + 'Z'\n",
    "  #Os valores são inseridos na lista que estava vazia\n",
    "  lista_datatime_estacao_convencional.append(datetime_estacao_convencional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo a coluna Datetime no dataframe Estação Convencional\n",
    "data_estacao_convencional_read['Datetime'] = lista_datatime_estacao_convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime     object\n",
       "chuva       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um novo dataframe Estação Convencional apenas com as colunas Datetime e chuva\n",
    "# pois apenas elas serão usadas daqui para frente\n",
    "#E verificando o tipo dos dados das colunas para garantir que estão corretos\n",
    "data_estacao_convencional_pronto = data_estacao_convencional_read[['Datetime', 'chuva']]\n",
    "data_estacao_convencional_pronto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Os tipos dos dados estão corretos\n",
    "#Fim da análise dos dados e ajuste do dataframe Estação Convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Início da análise comparativa entre os dois dataframes para poder usar os dados de chuva\n",
    "# do dataframe Estação Convencional junto com os dados do dataframe Sensor FieldPRO\n",
    "# para criar um modelo preditivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando as datas e horários que iniciam e terminam os dois dataframes para\n",
    "# identificar a intersecção dos dados, pois essa intersecção que será usada no modelo\n",
    "\n",
    "#O min() serva para identificar o menor valor da coluna, por se tradar de data\n",
    "# o min() informa a data mais antiga, o max() informa a mais nova, já que traz\n",
    "# o maior valor\n",
    "inicio_sensor_fielpro = data_sensor_pronto['Datetime'].min()\n",
    "fim_sensor_fielpro = data_sensor_pronto['Datetime'].max()\n",
    "inicio_estacao_convencional = data_estacao_convencional_pronto['Datetime'].min()\n",
    "fim_estacao_convencional = data_estacao_convencional_pronto['Datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataframe            Data_inicio              Data_fim\n",
      "0      Sensor_FieldPRO  2020-09-30T23:00:00Z  2020-12-11T13:00:00Z\n",
      "1  Estacao_Convecional  2020-09-01T00:00:00Z  2020-12-03T23:00:00Z\n"
     ]
    }
   ],
   "source": [
    "#Criando uma tabela para comparar os datetimes de início e fim de cada dataframe\n",
    "datas_inicio_fim = [['Sensor_FieldPRO', inicio_sensor_fielpro, fim_sensor_fielpro], ['Estacao_Convecional', inicio_estacao_convencional, fim_estacao_convencional]]\n",
    "comparacao_datas = pd.DataFrame(datas_inicio_fim, columns=['Dataframe ', 'Data_inicio', 'Data_fim'])\n",
    "print(comparacao_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa comparação mostra que o dataframe Estação Convencional tem dados iniciando antes dos dados\n",
    "# do Sensor FiledPRO, pois inicia as 00 horas do dia 01/09/20 enquanto o Sensor FieldPRO\n",
    "# inicia apenas as 23 horas do dia 30/09/20\n",
    "#Ao mesmo tempo o dataframe Estação Convencional finaliza seus dados antes, pois termina\n",
    "# as 23 horas do dia 03/12/20, enquanto no Sensor FieldPRO finaliza as 13 horas do dia\n",
    "# 11/12/20. Por tanto a intersecção de horários é entre 2020-09-30T23:00:00Z e 2020-12-03T23:00:00Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as variáveis data_inicio e data_fim que são os datetimes de início e fim\n",
    "# da instersecção dos dois dataframes\n",
    "data_inicio = inicio_sensor_fielpro\n",
    "data_fim = fim_estacao_convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR percorre os dois dataframes procurnando os valores de Datetime que são iguais para criar uma lista\n",
    "# com os valores de chuva da intersecção\n",
    "\n",
    "#Criando uma lista vazia para receber os valores de chuva\n",
    "lista_interseccao_chuva = []\n",
    "#O FOR é usado para passar por todos os valores de chuva do Estação Convencional\n",
    "for i in range(len(data_estacao_convencional_pronto['Datetime'])):\n",
    "  #O segundo FOR passa por tados os valores de datetime do Sensor FieldPRO\n",
    "  for j in range(len(data_sensor_pronto['Datetime'])):\n",
    "    #O IF compara se os valores de datetime de ambos os dataframes são iguais\n",
    "    if data_estacao_convencional_pronto['Datetime'][i] == data_sensor_pronto['Datetime'][j]:\n",
    "      #Caso sejam o valor da chuva é adicionado a lista que estava vazia\n",
    "      lista_interseccao_chuva.append(data_estacao_convencional_pronto['chuva'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando variaveis baseadas nos índices para serem usadas para delimitar \n",
    "# o dataframe Sensor FiledPRO entre os datetimes da instersecção\n",
    "indice_inicio = int(data_sensor_pronto[data_sensor_pronto['Datetime']== data_inicio].index.values)\n",
    "#O indice do fim precisa ter 1 somado pois quando informado no iloc vai do número de início até o final menos 1\n",
    "indice_fim = int(data_sensor_pronto[data_sensor_pronto['Datetime']== data_fim].index.values)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um novo dataframe para o Senfor FieldPRO com apenas os datetimes da instersecção\n",
    "data_sensor_intersec = data_sensor_pronto.iloc[indice_inicio:indice_fim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhkal\\AppData\\Local\\Temp\\ipykernel_11996\\3315192329.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_sensor_intersec['chuva'] = lista_interseccao_chuva\n"
     ]
    }
   ],
   "source": [
    "#Adicionando a lista de chuva ao dataframe Senfor FieldPRO e criando o dataframe\n",
    "#que será usado nos modelos\n",
    "data_sensor_intersec['chuva'] = lista_interseccao_chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora será aplicada a Regressão Linear nos dados para que o modelo aprenda com o padrão de dados\n",
    "# e possa prever quais serão as chuvas baseado nos dados como número de resets, piezo charge e piezo temperatura\n",
    "#Para garantir que o modelo está com a melhor previsão possível serão feitas diversas modelagens\n",
    "# em cada uma variando os dados de entrada do modelo, para depois comparar qual modelo gerou a \n",
    "# melhor previsão e usar este para prever as chuvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são o número de resets, piezo charge e piezo temperatura\n",
    "# e estão sendo feitas combinações dessas 3 colunas com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "\n",
    "\n",
    "dados1 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','chuva']]\n",
    "dados2 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100',\n",
    "                                      'atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0\n",
    "#As listas de Erro Absoluto Médio e Erro Médio percentual são criadas\n",
    "# para receber os valores dos erros para que futuramente seja feita a comparação\n",
    "lista_erro_abs_medio = [] \n",
    "lista_erro_medio_perc = [] \n",
    "#A variável parte é criada para definir a quantidade de linhas que serão usadas\n",
    "# nos dataframes de treino e teste, no caso estão sendo usadas 80% das linhas\n",
    "# para treino e 20% para teste\n",
    "parte = round(len(dados1)*0.8)\n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7\n",
    "while i<8: \n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo\n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são o número de resets e piezo charge\n",
    "# e estão sendo feitas combinações dessas 2 colunas com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "dados1 = data_sensor_intersec[['num_of_resets',\t'piezo_charge','chuva']]\n",
    "dados2 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['num_of_resets',\t'piezo_charge', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['num_of_resets',\t'piezo_charge', 'air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['num_of_resets',\t'piezo_charge',\t'air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['num_of_resets',\t'piezo_charge','air_humidity_100',\t'air_temperature_100', 'atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0 \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo\n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são o número de resets e piezo temperatura\n",
    "# e estão sendo feitas combinações dessas 2 colunas com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "dados1 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','chuva']]\n",
    "dados2 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['num_of_resets',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100', 'atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0  \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo\n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são o piezo charge e piezo temperatura\n",
    "# e estão sendo feitas combinações dessas 2 colunas com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "dados1 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','chuva']]\n",
    "dados2 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['piezo_charge',\t'piezo_temperature','air_humidity_100',\t'air_temperature_100','atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0 \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo\n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são apenas o número de resets\n",
    "# e estão sendo feitas combinações dessa coluna com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "dados1 = data_sensor_intersec[['num_of_resets','chuva']]\n",
    "dados2 = data_sensor_intersec[['num_of_resets','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['num_of_resets',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['num_of_resets', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['num_of_resets','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['num_of_resets','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['num_of_resets','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['num_of_resets','air_humidity_100',\t'air_temperature_100','atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0 \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo\n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são apenas piezo charge \n",
    "# e estão sendo feitas combinações dessa coluna com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "dados1 = data_sensor_intersec[['piezo_charge','chuva']]\n",
    "dados2 = data_sensor_intersec[['piezo_charge','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['piezo_charge',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['piezo_charge', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['piezo_charge','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['piezo_charge','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['piezo_charge','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['piezo_charge','air_humidity_100',\t'air_temperature_100','atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0 \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo \n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  Y = treino[['chuva']]\n",
    "  mod.fit(X, Y)\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  erro = Y_real - Y_prev\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesse bloco os dados usados são apenas de piezo temperatura\n",
    "# e estão sendo feitas combinações dessa coluna com as 3 colunas de dados extras\n",
    "# a humidade do ar, a temperatura do ar e a pressão atmosférica\n",
    "#Cada modelo gerado terá seu Erro Absoluto Médio e Erro Médio Percentual calculados\n",
    "# com objetivo de comparar e identificar o melhor modelo\n",
    "dados1 = data_sensor_intersec[['piezo_temperature','chuva']]\n",
    "dados2 = data_sensor_intersec[['piezo_temperature','air_humidity_100','chuva']]\n",
    "dados3 = data_sensor_intersec[['piezo_temperature',\t'air_temperature_100','chuva']]\n",
    "dados4 = data_sensor_intersec[['piezo_temperature', 'atm_pressure_main','chuva']]\n",
    "dados5 = data_sensor_intersec[['piezo_temperature','air_humidity_100',\t'air_temperature_100','chuva']]                                                                                                                \n",
    "dados6 = data_sensor_intersec[['piezo_temperature','air_humidity_100', 'atm_pressure_main','chuva']]  \n",
    "dados7 = data_sensor_intersec[['piezo_temperature','air_temperature_100', 'atm_pressure_main','chuva']]  \n",
    "dados8 = data_sensor_intersec[['piezo_temperature','air_humidity_100',\t'air_temperature_100','atm_pressure_main','chuva']]                                                                              \n",
    "#O i será usado no loop do while\n",
    "i = 0 \n",
    "#O mod está chamando a função da Regressão Linear\n",
    "mod = LinearRegression()\n",
    "#O WHILE foi usado para gerar um loop e rodar todas as cobinações de colunas\n",
    "# como são 7 combinações o looping roda 7 vezes\n",
    "while i<8:\n",
    "  #Os dataframes de treino tem os dados do dataframe de origem mas só vai até 80%\n",
    "  # das linhas, enquanto que os de teste ficam com os 20% de linhas restantes\n",
    "  #X é o dataframe que será usado no modelo para treino, ele possuí as mesmas \n",
    "  # colunas que o dataframe de origem, exceto pela coluna de chuva\n",
    "  #X_prev segue a mesma lógica, mas para o teste do modelo \n",
    "  if i == 0: \n",
    "    treino = dados1.iloc[0:parte] \n",
    "    teste = dados1.iloc[parte:len(dados1)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 1:\n",
    "    treino = dados2.iloc[0:parte] \n",
    "    teste = dados2.iloc[parte:len(dados2)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 2:\n",
    "    treino = dados3.iloc[0:parte] \n",
    "    teste = dados3.iloc[parte:len(dados3)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 3:\n",
    "    treino = dados4.iloc[0:parte] \n",
    "    teste = dados4.iloc[parte:len(dados4)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 4:\n",
    "    treino = dados5.iloc[0:parte] \n",
    "    teste = dados5.iloc[parte:len(dados5)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 5:\n",
    "    treino = dados6.iloc[0:parte] \n",
    "    teste = dados6.iloc[parte:len(dados6)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 6:\n",
    "    treino = dados7.iloc[0:parte] \n",
    "    teste = dados7.iloc[parte:len(dados7)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "  elif i == 7:\n",
    "    treino = dados8.iloc[0:parte] \n",
    "    teste = dados8.iloc[parte:len(dados8)] \n",
    "    X = treino.iloc[:, 0:treino.shape[1]-1 ] \n",
    "    X_prev = teste.iloc[:, 0:teste.shape[1]-1 ]\n",
    "\n",
    "  #O Y será usado para o treino e tem os valores de chuva\n",
    "  Y = treino[['chuva']]\n",
    "  #O mod.fit aplica a Rgressão Linear nos dataframes X e Y\n",
    "  mod.fit(X, Y)\n",
    "  #Y_prev é a previsão dos valores de chuva usando os dados do modelo de teste X_prev\n",
    "  Y_prev = mod.predict(X_prev)\n",
    "  #Y_real são os dados reais de chuva do X_prev\n",
    "  Y_real = teste[['chuva']].to_numpy()\n",
    "  #O erro é calculado fazendo a diferença entre a chuva real do Y_real \n",
    "  #com a chuva prevista do Y_prev\n",
    "  erro = Y_real - Y_prev\n",
    "  #O Erro Absoluto Médio é calculado através do valor absoluto do erro\n",
    "  erro_abs_medio = np.mean(abs(erro))\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_abs_medio.append(erro_abs_medio)\n",
    "  #O Erro Médio percentual é calculado dividindo o Erro Absoluto Médio pelo valor real de chuva\n",
    "  erro_medio_perc = erro_abs_medio/np.mean(Y_real)\n",
    "  #O valor do erro é adicionado na lista de erros\n",
    "  lista_erro_medio_perc.append(erro_medio_perc)\n",
    "  i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foram um total de 49 combinações de colunas sendo aplicadas no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora criamos um dataframe com os valores de Erro Absoluto Médio e Erro Médio percentual\n",
    "# para comparar os valores e identificar qual modelo gerou a previsão com menores erros\n",
    "\n",
    "#O tipo do dado foi definido como float pois terá casas decimais\n",
    "data_erros = pd.DataFrame(lista_erro_abs_medio, columns =['Abs_medio'], dtype = float)\n",
    "data_erros['Medio_percent'] = lista_erro_medio_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abs_medio</th>\n",
       "      <th>Medio_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370363</td>\n",
       "      <td>2.564049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.381418</td>\n",
       "      <td>2.640584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372339</td>\n",
       "      <td>2.577732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313929</td>\n",
       "      <td>2.173357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405497</td>\n",
       "      <td>2.807289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.326677</td>\n",
       "      <td>2.261613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300189</td>\n",
       "      <td>2.078230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.340091</td>\n",
       "      <td>2.354476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.383321</td>\n",
       "      <td>2.653758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.359060</td>\n",
       "      <td>2.485798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.366155</td>\n",
       "      <td>2.534917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.341658</td>\n",
       "      <td>2.365324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.407118</td>\n",
       "      <td>2.818513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.301234</td>\n",
       "      <td>2.085463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.302607</td>\n",
       "      <td>2.094969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.350035</td>\n",
       "      <td>2.423319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.327992</td>\n",
       "      <td>2.270711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.339386</td>\n",
       "      <td>2.349597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.325011</td>\n",
       "      <td>2.250076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.285888</td>\n",
       "      <td>1.979225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.352740</td>\n",
       "      <td>2.442046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.299246</td>\n",
       "      <td>2.071706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.272385</td>\n",
       "      <td>1.885742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.303788</td>\n",
       "      <td>2.103146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.212834</td>\n",
       "      <td>1.473467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.245664</td>\n",
       "      <td>1.700749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.209644</td>\n",
       "      <td>1.451381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.206930</td>\n",
       "      <td>1.432593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.248001</td>\n",
       "      <td>1.716933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.239121</td>\n",
       "      <td>1.655451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.203928</td>\n",
       "      <td>1.411810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.238232</td>\n",
       "      <td>1.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.339535</td>\n",
       "      <td>2.350630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.321041</td>\n",
       "      <td>2.222592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.323467</td>\n",
       "      <td>2.239388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.307735</td>\n",
       "      <td>2.130471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.357117</td>\n",
       "      <td>2.472351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.281162</td>\n",
       "      <td>1.946509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.276484</td>\n",
       "      <td>1.914118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.312928</td>\n",
       "      <td>2.166421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.218684</td>\n",
       "      <td>1.513968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.224918</td>\n",
       "      <td>1.557123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.210721</td>\n",
       "      <td>1.458840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.200131</td>\n",
       "      <td>1.385523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.249714</td>\n",
       "      <td>1.728787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.228891</td>\n",
       "      <td>1.584632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.205907</td>\n",
       "      <td>1.425513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.240955</td>\n",
       "      <td>1.668147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.211274</td>\n",
       "      <td>1.462667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.246161</td>\n",
       "      <td>1.704194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.208093</td>\n",
       "      <td>1.440645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.204220</td>\n",
       "      <td>1.413827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.248494</td>\n",
       "      <td>1.720342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.240183</td>\n",
       "      <td>1.662804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.201843</td>\n",
       "      <td>1.397373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.239417</td>\n",
       "      <td>1.657505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Abs_medio  Medio_percent\n",
       "0    0.370363       2.564049\n",
       "1    0.381418       2.640584\n",
       "2    0.372339       2.577732\n",
       "3    0.313929       2.173357\n",
       "4    0.405497       2.807289\n",
       "5    0.326677       2.261613\n",
       "6    0.300189       2.078230\n",
       "7    0.340091       2.354476\n",
       "8    0.383321       2.653758\n",
       "9    0.359060       2.485798\n",
       "10   0.366155       2.534917\n",
       "11   0.341658       2.365324\n",
       "12   0.407118       2.818513\n",
       "13   0.301234       2.085463\n",
       "14   0.302607       2.094969\n",
       "15   0.350035       2.423319\n",
       "16   0.327992       2.270711\n",
       "17   0.339386       2.349597\n",
       "18   0.325011       2.250076\n",
       "19   0.285888       1.979225\n",
       "20   0.352740       2.442046\n",
       "21   0.299246       2.071706\n",
       "22   0.272385       1.885742\n",
       "23   0.303788       2.103146\n",
       "24   0.212834       1.473467\n",
       "25   0.245664       1.700749\n",
       "26   0.209644       1.451381\n",
       "27   0.206930       1.432593\n",
       "28   0.248001       1.716933\n",
       "29   0.239121       1.655451\n",
       "30   0.203928       1.411810\n",
       "31   0.238232       1.649300\n",
       "32   0.339535       2.350630\n",
       "33   0.321041       2.222592\n",
       "34   0.323467       2.239388\n",
       "35   0.307735       2.130471\n",
       "36   0.357117       2.472351\n",
       "37   0.281162       1.946509\n",
       "38   0.276484       1.914118\n",
       "39   0.312928       2.166421\n",
       "40   0.218684       1.513968\n",
       "41   0.224918       1.557123\n",
       "42   0.210721       1.458840\n",
       "43   0.200131       1.385523\n",
       "44   0.249714       1.728787\n",
       "45   0.228891       1.584632\n",
       "46   0.205907       1.425513\n",
       "47   0.240955       1.668147\n",
       "48   0.211274       1.462667\n",
       "49   0.246161       1.704194\n",
       "50   0.208093       1.440645\n",
       "51   0.204220       1.413827\n",
       "52   0.248494       1.720342\n",
       "53   0.240183       1.662804\n",
       "54   0.201843       1.397373\n",
       "55   0.239417       1.657505"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando o dataframe de erros para comparar os valores e identificar qual\n",
    "# modelo teve o melhor resultado\n",
    "data_erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Os menores valores de erro foram da linha 43\n",
    "#Ou seja foram do conjunto de dados que tem as colunas piezo charge e humidade do ar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um dataframe com as colunas que geram o melhor modelo\n",
    "data_melhor_modelo = data_sensor_intersec[['piezo_charge','air_humidity_100','chuva']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui será aplicado novamento a Regressão Linear, mas apenas no melhor modelo\n",
    "# para mostrar os valores de chuva previstos\n",
    "parte = round(len(data_melhor_modelo)*0.8)\n",
    "treino = data_melhor_modelo.iloc[0:parte]\n",
    "teste = data_melhor_modelo.iloc[parte:len(data_melhor_modelo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = treino[['chuva']]\n",
    "X = treino[['piezo_charge',\t'air_humidity_100']]\n",
    "X_prev = teste[['piezo_charge',\t'air_humidity_100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = LinearRegression()\n",
    "mod.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prev = mod.predict(X_prev)\n",
    "Y_real = teste[['chuva']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora está sendo criado o dataframe com os valores de chuva previstos e seus datetimes\n",
    "data_previsao = data_sensor_intersec['Datetime'].iloc[parte:len(data_melhor_modelo)]\n",
    "data_previsao = data_previsao.to_frame()\n",
    "data_previsao['chuva'] = Y_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetando o índice do dataframe\n",
    "data_previsao = data_previsao.reset_index()\n",
    "data_previsao = data_previsao.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arredondando o valor da chuva para ter apenas duas casas decimais\n",
    "# pois os dados originais tinham apenas duas casas decimais\n",
    "data_previsao = data_previsao.round({'chuva': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os valores de data e hora no dataframe para melhorar a visualização\n",
    "#A função split separa o texto a partir de um identificador que no caso é o 'T'\n",
    "data_datetime = data_previsao['Datetime'].str.split('T', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma coluna apenas com os valores de data e no padrão de data usado no Brasil\n",
    "#O data_datetime ficou com duas listas, o [0] é para informar que a data está na \n",
    "# primeira lista\n",
    "data_previsao['Data'] = data_datetime[0]\n",
    "data_previsao['Data'] = pd.to_datetime(data_previsao.Data)\n",
    "data_previsao['Data'] = data_previsao['Data'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma coluna apenas com os valores de Hora\n",
    "#O datetime[1] é a lista com horários, mas ainda tinha o 'Z', \n",
    "# então o 'Z' foi removido\n",
    "data_datetime[1] = data_datetime[1].str.replace('Z', '')\n",
    "data_previsao['Hora'] = data_datetime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Hora</th>\n",
       "      <th>chuva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21/11/2020</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22/11/2020</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22/11/2020</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data      Hora  chuva\n",
       "0   21/11/2020  06:00:00   0.14\n",
       "1   21/11/2020  07:00:00   0.15\n",
       "2   21/11/2020  08:00:00   0.16\n",
       "3   21/11/2020  09:00:00   0.15\n",
       "4   21/11/2020  10:00:00   0.11\n",
       "5   21/11/2020  11:00:00   0.08\n",
       "6   21/11/2020  12:00:00   0.06\n",
       "7   21/11/2020  13:00:00   0.04\n",
       "8   21/11/2020  14:00:00   0.02\n",
       "9   21/11/2020  15:00:00   0.03\n",
       "10  21/11/2020  16:00:00  -0.01\n",
       "11  21/11/2020  17:00:00  -0.02\n",
       "12  21/11/2020  18:00:00  -0.02\n",
       "13  21/11/2020  19:00:00  -0.05\n",
       "14  21/11/2020  20:00:00  -0.04\n",
       "15  21/11/2020  21:00:00  -0.02\n",
       "16  21/11/2020  22:00:00   0.03\n",
       "17  21/11/2020  23:00:00   0.05\n",
       "18  22/11/2020  00:00:00   0.04\n",
       "19  22/11/2020  01:00:00   0.05"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Organizando as colunas do dataframe\n",
    "data_previsao = data_previsao[['Data', 'Hora', 'chuva']]\n",
    "data_previsao.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foi observado que alguns dos valores de chuva previstos estão negativos\n",
    "#Como não é possível ter valores negativos e os valores negativos são próximos de \n",
    "# zero, será feita uma subtituição desses valores por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O FOR é usado para verificar quais são os valores negativos e substuir por zero\n",
    "#Criando uma lista vazia para receber os valores de chuva\n",
    "lista_chuva_sem_negativos = []\n",
    "#O FOR percorre os valores da segunda coluna do dataframe data_previsao\n",
    "for i in range(len(data_previsao.iloc[:,2])):\n",
    "  #O IF compara os valores de chuva para ver se são menores que 0.1\n",
    "  if data_previsao.iloc[i,2] < 0.01 :\n",
    "    #Caso sejam eles são subtituidos por 0\n",
    "    lista_chuva_sem_negativos.append(0)\n",
    "  else:\n",
    "    #Caso não sejam eles permanecem com são\n",
    "    lista_chuva_sem_negativos.append(data_previsao.iloc[i,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo os valores de chuva sem os negativos no dataframe\n",
    "data_previsao['chuva'] = lista_chuva_sem_negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustando no nome da coluna chuva para Previsão de chuva\n",
    "data_previsao = data_previsao.rename(columns={'chuva': 'Previsão de Chuva'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando o dataframe em html para poder subir para a cloud\n",
    "data_previsao.to_html('previsaodechuva.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
